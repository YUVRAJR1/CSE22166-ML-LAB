{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b748e1-717e-4179-95db-5695f8432b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (1.5.1)\n",
      "Requirement already satisfied: catboost in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: xgboost in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: shap in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: lime in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (0.2.0.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from catboost) (3.8.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from shap) (0.59.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from shap) (2.2.1)\n",
      "Requirement already satisfied: scikit-image>=0.12 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from lime) (0.23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (10.3.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2023.4.12)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from numba->shap) (0.42.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\yuvra\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn catboost xgboost shap lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e2317ac-bb02-453d-860c-607562b5819b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in c:\\users\\yuvra\\appdata\\roaming\\python\\python312\\site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "144a3a51-f748-4da9-a8ca-f49529e4eada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Perceptron...\n",
      "Tuning MLP...\n",
      "Best Perceptron Parameters:  {'tol': 0.001, 'penalty': 'l1', 'max_iter': 1000, 'alpha': 0.0001}\n",
      "Best Perceptron Score:  0.6294444444444445\n",
      "Best MLP Parameters:  {'solver': 'adam', 'max_iter': 300, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 50), 'alpha': 0.0001, 'activation': 'tanh'}\n",
      "Best MLP Score:  0.8427777777777777\n",
      "\n",
      "Perceptron Test Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        3333       0.30      0.33      0.32         9\n",
      "        3334       0.88      1.00      0.93         7\n",
      "        3335       0.92      0.92      0.92        13\n",
      "        3337       0.71      1.00      0.83         5\n",
      "        3342       0.75      0.60      0.67        15\n",
      "        3343       0.00      0.00      0.00         1\n",
      "        3346       0.88      0.88      0.88         8\n",
      "        3349       0.65      0.52      0.58        21\n",
      "        3350       0.00      0.00      0.00         1\n",
      "        3351       0.29      0.71      0.42         7\n",
      "        3352       0.50      0.27      0.35        15\n",
      "        3353       0.77      0.77      0.77        13\n",
      "        3354       0.71      0.75      0.73        16\n",
      "        3355       0.00      0.00      0.00         0\n",
      "        3356       0.80      0.67      0.73         6\n",
      "        3357       0.00      0.00      0.00         1\n",
      "        3358       0.00      0.00      0.00         1\n",
      "        3359       0.81      0.76      0.79        17\n",
      "        3360       0.17      0.29      0.21         7\n",
      "        3361       0.60      1.00      0.75         3\n",
      "        3362       1.00      1.00      1.00         3\n",
      "        3363       0.91      1.00      0.95        10\n",
      "        3364       0.14      0.40      0.21         5\n",
      "        3365       1.00      0.50      0.67         4\n",
      "        3366       0.62      0.62      0.62         8\n",
      "        3367       0.57      0.67      0.62         6\n",
      "        3368       0.57      0.22      0.32        18\n",
      "        3370       0.55      0.86      0.67         7\n",
      "        3371       1.00      0.67      0.80         3\n",
      "        3372       0.62      1.00      0.77         5\n",
      "        3373       0.39      1.00      0.56        12\n",
      "        3374       0.83      0.50      0.62        20\n",
      "        3375       0.67      0.57      0.62        14\n",
      "        3376       0.71      0.43      0.54        23\n",
      "        3377       0.59      0.87      0.70        15\n",
      "        3378       0.25      0.22      0.24         9\n",
      "        3379       1.00      0.71      0.83         7\n",
      "        3380       1.00      1.00      1.00         2\n",
      "        3381       1.00      0.50      0.67        14\n",
      "        3382       0.58      0.70      0.64        10\n",
      "        3383       0.67      0.43      0.52        14\n",
      "        3384       0.67      0.47      0.55        17\n",
      "        3385       0.88      0.82      0.85        17\n",
      "        3450       1.00      1.00      1.00         6\n",
      "        3451       0.65      1.00      0.79        11\n",
      "        3452       0.77      0.62      0.69        16\n",
      "        3453       1.00      0.60      0.75         5\n",
      "        3454       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.64       450\n",
      "   macro avg       0.62      0.62      0.60       450\n",
      "weighted avg       0.69      0.64      0.64       450\n",
      "\n",
      "\n",
      "MLP Test Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        3333       0.70      0.78      0.74         9\n",
      "        3334       0.88      1.00      0.93         7\n",
      "        3335       1.00      1.00      1.00        13\n",
      "        3337       1.00      1.00      1.00         5\n",
      "        3342       1.00      0.80      0.89        15\n",
      "        3343       0.00      0.00      0.00         1\n",
      "        3346       1.00      1.00      1.00         8\n",
      "        3349       0.95      0.86      0.90        21\n",
      "        3350       0.00      0.00      0.00         1\n",
      "        3351       0.00      0.00      0.00         7\n",
      "        3352       0.30      0.20      0.24        15\n",
      "        3353       1.00      1.00      1.00        13\n",
      "        3354       1.00      0.94      0.97        16\n",
      "        3355       0.00      0.00      0.00         0\n",
      "        3356       0.86      1.00      0.92         6\n",
      "        3357       0.00      0.00      0.00         1\n",
      "        3358       0.00      0.00      0.00         1\n",
      "        3359       1.00      0.94      0.97        17\n",
      "        3360       0.64      1.00      0.78         7\n",
      "        3361       1.00      1.00      1.00         3\n",
      "        3362       1.00      1.00      1.00         3\n",
      "        3363       0.83      1.00      0.91        10\n",
      "        3364       0.67      0.80      0.73         5\n",
      "        3365       1.00      0.50      0.67         4\n",
      "        3366       1.00      0.88      0.93         8\n",
      "        3367       0.75      1.00      0.86         6\n",
      "        3368       0.82      0.78      0.80        18\n",
      "        3370       0.83      0.71      0.77         7\n",
      "        3371       1.00      1.00      1.00         3\n",
      "        3372       0.83      1.00      0.91         5\n",
      "        3373       1.00      1.00      1.00        12\n",
      "        3374       0.90      0.90      0.90        20\n",
      "        3375       1.00      0.50      0.67        14\n",
      "        3376       0.87      0.87      0.87        23\n",
      "        3377       0.93      0.93      0.93        15\n",
      "        3378       0.67      0.89      0.76         9\n",
      "        3379       1.00      0.86      0.92         7\n",
      "        3380       1.00      1.00      1.00         2\n",
      "        3381       0.81      0.93      0.87        14\n",
      "        3382       1.00      1.00      1.00        10\n",
      "        3383       1.00      0.93      0.96        14\n",
      "        3384       1.00      0.88      0.94        17\n",
      "        3385       0.94      1.00      0.97        17\n",
      "        3450       1.00      1.00      1.00         6\n",
      "        3451       1.00      1.00      1.00        11\n",
      "        3452       0.78      0.88      0.82        16\n",
      "        3453       0.83      1.00      0.91         5\n",
      "        3454       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.86       450\n",
      "   macro avg       0.78      0.79      0.78       450\n",
      "weighted avg       0.87      0.86      0.86       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuvra\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#### A1 ####\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, ShuffleSplit\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(\"D:/_STUDIES/ML/DCT_withoutduplicate 3 (1).csv\")\n",
    "\n",
    "# Split the data into features (X) and target labels (y)\n",
    "X = df.drop('LABEL', axis=1)  # Dropping the target column to get features\n",
    "y = df['LABEL']  # Extracting the target column\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# 80% of data will be used for training, and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features using StandardScaler\n",
    "# This scales features to have zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit on training data and transform it\n",
    "X_test = scaler.transform(X_test)  # Transform test data based on training fit\n",
    "\n",
    "# Define the parameter grid for Perceptron model tuning\n",
    "perceptron_params = {\n",
    "    'penalty': ['l1', 'l2', None],  # Penalty type (L1, L2, or None)\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # Regularization strength\n",
    "    'tol': [1e-3, 1e-4, 1e-2],  # Tolerance for stopping criteria\n",
    "    'max_iter': [1000, 2000, 3000]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Define the parameter grid for MLPClassifier model tuning\n",
    "mlp_params = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50)],  # Different network architectures\n",
    "    'activation': ['relu', 'tanh'],  # Activation functions\n",
    "    'solver': ['adam', 'sgd'],  # Optimizers\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # Regularization term (L2 penalty)\n",
    "    'learning_rate': ['constant', 'adaptive'],  # Learning rate schedule\n",
    "    'max_iter': [300, 500, 1000]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# ShuffleSplit cross-validation: splits the data randomly multiple times (5 times here)\n",
    "# Each time, 20% of the data is used for validation\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tuning the Perceptron model using RandomizedSearchCV\n",
    "# RandomizedSearchCV randomly samples hyperparameters from the grid and evaluates them\n",
    "print(\"Tuning Perceptron...\")\n",
    "perceptron = Perceptron(class_weight='balanced')  # Initialize Perceptron with balanced class weights\n",
    "perceptron_search = RandomizedSearchCV(\n",
    "    perceptron, perceptron_params, n_iter=10, scoring='accuracy', cv=cv, random_state=42, n_jobs=-1\n",
    ")\n",
    "perceptron_search.fit(X_train, y_train)  # Train the model using cross-validation\n",
    "\n",
    "# Tuning the MLP (Multi-Layer Perceptron) model\n",
    "print(\"Tuning MLP...\")\n",
    "mlp = MLPClassifier()  # Initialize MLPClassifier\n",
    "mlp_search = RandomizedSearchCV(\n",
    "    mlp, mlp_params, n_iter=10, scoring='accuracy', cv=cv, random_state=42, n_jobs=-1\n",
    ")\n",
    "mlp_search.fit(X_train, y_train)  # Train the model using cross-validation\n",
    "\n",
    "# Print the best hyperparameters and cross-validation scores for both models\n",
    "print(\"Best Perceptron Parameters: \", perceptron_search.best_params_)\n",
    "print(\"Best Perceptron Score: \", perceptron_search.best_score_)\n",
    "print(\"Best MLP Parameters: \", mlp_search.best_params_)\n",
    "print(\"Best MLP Score: \", mlp_search.best_score_)\n",
    "\n",
    "# Predict the target labels for the test set using the best models found\n",
    "y_pred_perceptron = perceptron_search.predict(X_test)\n",
    "y_pred_mlp = mlp_search.predict(X_test)\n",
    "\n",
    "# Performance report for Perceptron on the test data\n",
    "print(\"\\nPerceptron Test Performance\")\n",
    "print(classification_report(y_test, y_pred_perceptron, zero_division=0))  # zero_division handles cases where no class exists\n",
    "\n",
    "# Performance report for MLP on the test data\n",
    "print(\"\\nMLP Test Performance\")\n",
    "print(classification_report(y_test, y_pred_mlp, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775359e-779b-4d90-b619-c66400c06ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f4da5-a324-46aa-bb46-37a05795a11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f7faec-f6a1-4810-a8d0-efa4c797a9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa095849-f198-45b4-acd6-3b5741b1ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca4c4e-0be6-4d49-84a4-d7e0eb9eae9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4c02a-7882-46aa-b1f2-7c1458278daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
